CLUSTERING (Unsupervised)
data center computing cluster organization, segmentation
no y labels
K Means Algorithm 
    cluster assignment: assign to cluster centroid depending on distance
    cluster moving: move to mean location of associated cluster 
    cluster assignment 2: reassign based on distance
    cluster moving 2: move to new mean
    cluster assignment and cluster moving one more time
    input: K, number of clusters; training set {x^1, ..., x^m}
    algorithm randomly initializes K cluster centroids, mu1,...,muk
      repeat{
          for i=m
            c^1 := index (from 1 to K) of cluster centroid closest to x^i  (find value of k that minimized distance)
          for k=1 to K
            muk:=average of points assigned to cluster (cluster centroid notation)
Optimization objective
 mc^i = cluster centroid of cluster to whicj example x^i has been assigned
J(c^1,...,c^m,mu1,...,muk) = 1/m * summ ||x^i - muc^i||^2     (minimize the cost function, or distortioon)
first loop is minimizing J(...) with c holding mu fixed.  second loop is minizing J(...) with mu, holding c fixed
Random Initialization
K<m, randomly pick K training examples, set mu1,...,muk equal to these K examples aka pick k distinct random integers i1...1k from {1...m} set mu1=x^(i1), mu2=x^(i2),...,muk=x^(ik)
can end up at local optima...try multiple random initializations and try multiple k means  
      for i=1 to (50-1000) {
          Randomly initialize K-means
          Run Kmean. Get c^1,...,c^m,mu1,...,muK
          Compute cost function (distortion)
              J(c^1,...,c^m,mu1,...,muK)
              }
      Pick clustering that gave lowest cost
Choosing number of clusters
Elbow method:when the rate of decrease of the cost function slows down
You can also evaluate kmeans based on a metric for how well it performs for that later purpose

MOTIVATION
Data Compression/Dimensionality Reduction
Reduce 2d to 1d, z is new feature for location of point
Suppose we apply dimensionality reduction to a dataset of m examples {x^1,...x^m} where x^i is within R^n. As a result of this, we will get out a lower dimensional dataset {z^1,...,z^m} of m examples where z^i is within R^k for some value k and k<=n 
Visualization
PRINCIPAL COMPONENT ANALYSIS 
APPLYING PCA
